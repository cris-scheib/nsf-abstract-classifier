{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ede30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the .xml files and create a .csv with only the needed information \n",
    "# Uses the AwardTitle and the AbstractNarration information to create the dataset\n",
    "\n",
    "import os, glob\n",
    "import csv\n",
    "\n",
    "# Get the data from the .xml tags\n",
    "def filterData(data, tag):\n",
    "    startTag = \"<%s>\" % (tag)\n",
    "    endTag = \"</%s>\" % (tag)\n",
    "    start = data.find(startTag) + len(startTag)\n",
    "    end = data.find(endTag)\n",
    "    return data[start:end]\n",
    "\n",
    "#Clean the data removing unnecessary tag\n",
    "def cleanData(data):\n",
    "    startTag = \"<![CDATA[\"\n",
    "    endTag = \"]]>\"\n",
    "    if startTag in data:\n",
    "        data = data[len(startTag):-len(endTag)]\n",
    "    return data\n",
    "\n",
    "csvfile = open('abstract_narrations.csv', 'w')\n",
    "writer = csv.writer(csvfile)\n",
    "writer.writerow(['title', 'narration'])\n",
    "\n",
    "emptyTags = [\"<AwardTitle/>\", \"<AbstractNarration/>\"]\n",
    "\n",
    "for filename in glob.glob('files/*.xml'):\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r', encoding='UTF8') as f: # open in readonly mode\n",
    "        data = f.read()\n",
    "        if all(x not in data for x in emptyTags):\n",
    "            \n",
    "            title = filterData(data,\"AwardTitle\")\n",
    "            title = cleanData(title)\n",
    "            \n",
    "            narration = filterData(data,\"AbstractNarration\")\n",
    "            narration = cleanData(narration)\n",
    "            \n",
    "            writer.writerow([title, narration])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Case the file abstract_narrations.csv already exists the code above is not necessary\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce4bc48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('abstract_narrations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943e9ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99223155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['narration'] = df['narration'].str.lower()\n",
    "df['narration'] = df['narration'].str.replace('&lt;br/&gt;', '')\n",
    "df['narration'] = df['narration'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bcd3c018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>narration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adaptive dynamic coordination of damping contr...</td>\n",
       "      <td>[in, the, last, decades, global, environmental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAPID: On-mask Chemical Modulation of Respirat...</td>\n",
       "      <td>[non, technical, abstract, spread, of, infecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Collaborative Research: Biomass burning smoke ...</td>\n",
       "      <td>[microbes, are, found, in, all, environments, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBIR Phase I:  AK-423: A broad-spectrum antivi...</td>\n",
       "      <td>[the, broader, impact, commercial, potential, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Nature of Coupled Heat and Mass Transport ...</td>\n",
       "      <td>[the, goal, of, this, project, is, to, underst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Adaptive dynamic coordination of damping contr...   \n",
       "1  RAPID: On-mask Chemical Modulation of Respirat...   \n",
       "2  Collaborative Research: Biomass burning smoke ...   \n",
       "3  SBIR Phase I:  AK-423: A broad-spectrum antivi...   \n",
       "4  The Nature of Coupled Heat and Mass Transport ...   \n",
       "\n",
       "                                           narration  \n",
       "0  [in, the, last, decades, global, environmental...  \n",
       "1  [non, technical, abstract, spread, of, infecti...  \n",
       "2  [microbes, are, found, in, all, environments, ...  \n",
       "3  [the, broader, impact, commercial, potential, ...  \n",
       "4  [the, goal, of, this, project, is, to, underst...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0c4db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words('english')\n",
    "df['narration'] = df['narration'].apply(lambda x: [word for word in x if not word in all_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c72ba7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ef5768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d5aeec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "vocabulary_size = 25000\n",
    "\n",
    "def build_dataset(dataset):\n",
    "    narration = dataset['narration'].tolist()\n",
    "    narration = flatten(narration)\n",
    "\n",
    "    words = [['UNK', -1]]\n",
    "    words.extend(collections.Counter(narration).most_common(vocabulary_size - 1))\n",
    "\n",
    "    # Dicion√°rio\n",
    "    dictionary = dict()\n",
    "    for word, _ in words:\n",
    "        dictionary[word] = len(dictionary)\n",
    "\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "\n",
    "    for word in narration:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count = unk_count + 1\n",
    "        data.append(index)\n",
    "\n",
    "    words[0][1] = unk_count\n",
    "\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    assert len(dictionary) == vocabulary_size\n",
    "\n",
    "    return data, words, dictionary, reverse_dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca24608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, words, dictionary, reverse_dictionary = build_dataset(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
